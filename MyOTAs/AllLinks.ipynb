{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fc006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import io\n",
    "import common_functions\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f77e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_excel_and_csv(excel_file_path, file_path):\n",
    "    # Extract the date from the Excel file name\n",
    "    date_from_filename = os.path.basename(excel_file_path).split(' - ')[1].split(\".\")[0]\n",
    "\n",
    "    # Read all sheets from the Excel file into a single DataFrame\n",
    "    df_day = pd.concat(pd.read_excel(excel_file_path, sheet_name=None), ignore_index=True)\n",
    "\n",
    "    # Rename columns in df_day to match df_oper\n",
    "    df_day.rename(columns={\n",
    "            'Tytul': 'Tytul',\n",
    "            'Tytul URL': 'Link',\n",
    "            'Miasto': 'City',\n",
    "            'IloscOpini': 'Reviews',\n",
    "            'Data zestawienia': 'Date input'\n",
    "        }, inplace=True)\n",
    "    df_day['Date update'] = df_day['Date input']\n",
    "\n",
    "    df_day['Link'] = df_day['Link'].str.lower()\n",
    "\n",
    "    # Drop the columns from df_day that are not in df_oper\n",
    "    df_day = df_day[['Tytul', 'Link', 'City', 'Reviews', 'Date input', 'Date update']]\n",
    "\n",
    "    # Remove duplicates based on the 'Link' column\n",
    "    df_day = df_day.drop_duplicates(subset=['Link'])\n",
    "\n",
    "    \n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    # df_oper = pd.read_csv(file_path.replace('.csv', '.xlsx'))\n",
    "    df_oper = pd.read_excel(file_path)\n",
    "    df_oper['Link'] = df_oper['Link'].str.lower()\n",
    "    # Update the 'Reviews' in df_oper from df_day\n",
    "    df_oper_updated = pd.merge(df_oper, df_day[['Link', 'Reviews']], on='Link', how='left')\n",
    "    df_oper_updated['Reviews'] = df_oper_updated['Reviews_y'].combine_first(df_oper_updated['Reviews_x'])\n",
    "    df_oper_updated.drop(columns=['Reviews_x', 'Reviews_y'], inplace=True)\n",
    "\n",
    "    # Update 'Date update' for matched links\n",
    "    df_oper_updated.loc[df_oper_updated['Reviews'].notnull(), 'Date update'] = datetime.strptime(date_from_filename, '%Y-%m-%d')\n",
    "\n",
    "    # Merge df_oper on top of df_day\n",
    "    merged_df = pd.concat([df_oper_updated, df_day], ignore_index=True)\n",
    "\n",
    "    # Drop duplicates while keeping all rows from df_oper\n",
    "    merged_df = merged_df.drop_duplicates(subset='Link', keep='first')\n",
    "    merged_df = merged_df[~merged_df['Link'].isnull()]\n",
    "    merged_df['Link'] = merged_df['Link'].astype(str)\n",
    "    # Fill empty 'Operator' column entries with 'ToDo'\n",
    "    merged_df['Operator'] = merged_df['Operator'].fillna('ToDo')\n",
    "    # Clean GYG file\n",
    "    if 'GYG' in file_path:\n",
    "        merged_df['Reviews'] = merged_df['Reviews'].apply(lambda x: str(x).lower().replace('(', '').replace(')', '').replace('reviews', '') if len(str(x)) > 0 else '0')\n",
    "        merged_df['uid'] = merged_df['Link'].apply(lambda x: str(x).split('-')[-1].replace('/', ''))\n",
    "    elif \"Headout\" in file_path:\n",
    "        merged_df['Reviews'] = merged_df['Reviews'].fillna(0)\n",
    "        merged_df['Reviews'] = merged_df['Reviews'].str.replace('(', '').str.replace(')','')\n",
    "        merged_df['Reviews'] = merged_df['Reviews'].apply(lambda x: int(float(x.replace('K', '')) * 1000) if isinstance(x, str) and 'K' in x else x)\n",
    "        merged_df['uid'] = merged_df['Link'].apply(lambda x: str(x).split('-')[-1].replace('/', ''))\n",
    "    elif \"Musement\" in file_path:\n",
    "        merged_df['Reviews'] = merged_df['Reviews'].apply(lambda x: str(x).lower().replace('(', '').replace(')', '').replace('reviews', '') if len(str(x)) > 0 else '0')\n",
    "        merged_df['uid'] = merged_df['Link'].apply(lambda x: str(x).split('-')[-1].replace('/', ''))\n",
    "    else:\n",
    "        merged_df['uid'] = merged_df['Link'].apply(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "    \n",
    "    # Save the resulting DataFrame to a new file\n",
    "    output_file_path = os.path.join(file_path)\n",
    "    # merged_df.to_excel(output_file_path, index=False)\n",
    "  # Use XlsxWriter as the engine to write the Excel file\n",
    "    output = io.BytesIO()\n",
    "    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "        workbook = writer.book\n",
    "        workbook.strings_to_urls = False\n",
    "        merged_df.to_excel(writer, index=False, sheet_name='AllLinks')\n",
    "\n",
    "    with open(output_file_path, 'wb') as f:\n",
    "        f.write(output.getvalue())\n",
    "        \n",
    "    print(f\"Processed data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['GYG', 'Viator', 'Musement', 'Headout']\n",
    "for site in sites:\n",
    "    file_manager = common_functions.FilePathManager(site, 'N/A')\n",
    "    file_path_xlsx_operator = file_manager.get_file_paths()['file_path_xlsx_operator']\n",
    "    file_path_output = file_manager.get_file_paths()['file_path_output']\n",
    "    print(file_path_xlsx_operator)\n",
    "    print(file_path_output)\n",
    "    process_excel_and_csv(file_path_output, file_path_xlsx_operator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# file_path = file_path_xlsx_operator \n",
    "# process_excel_and_csv(output_viator + f\"/Viator - {date_today}.xlsx\", file_path, fr'G:\\.shortcut-targets-by-id\\1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2\\MyOTAs\\Pliki firmowe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_gyg = r'G:/.shortcut-targets-by-id/1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2/MyOTAs/Baza Excel/Get Your Guide/'\n",
    "# gyg_file_daily = output_gyg + f'GYG - {date_today}.xlsx'\n",
    "# file_path = file_path_xlsx_operator.replace('Operators_Groups.xlsx', 'Operators_GYG.xlsx')\n",
    "# process_excel_and_csv(gyg_file_daily, file_path, fr'G:\\.shortcut-targets-by-id\\1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2\\MyOTAs\\Pliki firmowe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_headout = r'G:/.shortcut-targets-by-id/1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2/MyOTAs/Baza Excel/Headout/Daily/'\n",
    "# headout_file_daily = output_headout + f'Headout - {date_today}.xlsx'\n",
    "# file_path = file_path_xlsx_operator.replace('Operators_Groups.xlsx', 'Operators_Headout.xlsx')\n",
    "# process_excel_and_csv(headout_file_daily, file_path, fr'G:\\.shortcut-targets-by-id\\1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2\\MyOTAs\\Pliki firmowe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_musement = r'G:/.shortcut-targets-by-id/1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2/MyOTAs/Baza Excel/Musement/Daily/'\n",
    "# musement_file_daily = output_musement + f'Musement - {date_today}.xlsx'\n",
    "# file_path = file_path_xlsx_operator.replace('Operators_Groups.xlsx', 'Operators_Musement.xlsx')\n",
    "# process_excel_and_csv(musement_file_daily, file_path, fr'G:\\.shortcut-targets-by-id\\1ER8hilqZ2TuX2C34R3SMAtd1Xbk94LE2\\MyOTAs\\Pliki firmowe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4528273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
